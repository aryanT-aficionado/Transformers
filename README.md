# ğŸš€ Transformers
This repository (and LinkedIn series) is about breaking down Transformersâ€”the deep learning models behind almost every major NLP breakthrough today.

Weâ€™ll start simple: what Transformers are, why they matter, and how they work step by step.

## ğŸ“Œ 1. What & Why Transformers?

Imagine youâ€™re using Google Translate:
```
English â†’ Spanish
"Hello, how are you?" â†’ "Hola, Â¿cÃ³mo estÃ¡s?"
```

Old models mightâ€™ve output:
> â€œHola, cÃ³mo eres tÃº?â€ âŒ (Literal, awkward)

Transformers get the **intent** â€” because they **pay attention**.

### ğŸ“Œ Encoder-Decoder Architecture 
Transformers are built around an **encoder-decoder** structure:

- **Encoder**: Reads the input sentence and creates a representation.
- **Decoder**: Takes that representation and generates the output sentence. 

**Problem with older encoder-decoder models (like RNNs/LSTMs):**
- As sentence length increases, they struggle.
- Translation quality drops, often measured by the **BLEU score** (a metric for translation accuracy).
Example:

```
English: "The quick brown fox jumps over the lazy dog near the river."
Spanish (bad translation): "El rÃ¡pido marrÃ³n zorro salta sobre perro
perezoso."
```

### ğŸ“Œ Attention Mechanism  

Hereâ€™s the fix: **attention**.  

Instead of only relying on the last hidden state of the encoder, attention lets the decoder look back at *all* input words and decide which ones matter most when generating each output word.

Example (English â†’ Spanish):

```
Input: "I love eating apples."
When predicting "me gusta comer manzanas",
- The model attends to "love" when generating "me gusta"
- Then to "eating" for "comer"
- Then to "apples" for "manzanas"
```

So the translation is context-aware.

### ğŸ“Œ Self-Attention (The Transformer Superpower)  

Regular attention works word by word. Transformers go further: they use **self-attention**, meaning:  

- Every word in a sentence looks at every other word, *in parallel*.  
- This allows scalingâ€”because instead of processing words one after another, Transformers handle them all at once.  

Example:  

Sentence: *"The animal didnâ€™t cross the street because it was too tired."*  

Which word does *â€œitâ€* refer to?  
- Self-attention helps the model figure out that *â€œitâ€* links back to *â€œthe animalâ€*, not *â€œthe streetâ€*. 

### ğŸ“Œ Contextual Embeddings  

Unlike older word embeddings (like Word2Vec) that gave one static vector per word, Transformers create **contextual embeddings**.  

Example:  

```
Word: "bank"
Sentence 1: "I deposited money in the bank."
Sentence 2: "The fisherman sat by the river bank."
```

Old models â†’ same embedding for â€œbank.â€  
Transformers â†’ different embeddings depending on context.  